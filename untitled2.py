# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gGg_ZtAW1sWZVpASIye0VQ95jCuSqowk

# Downloading datasets from roboflow
"""

!pip install roboflow
from roboflow import Roboflow

# 1.  https://universe.roboflow.com/andalas/license_plate-anq70
rf = Roboflow(api_key="YotJSFyYLj9EyAE88xO4")
project = rf.workspace("andalas").project("license_plate-anq70")
version = project.version(1)
dataset = version.download("yolov11")

# 2.  https://universe.roboflow.com/school-qpc33/dataset-mix
project = rf.workspace("school-qpc33").project("dataset-mix")
version = project.version(2)
dataset = version.download("yolov11")

# 3.  https://universe.roboflow.com/aqil-ihohn/deteksi-plat-nomor-kendaraan-k1ldk
project = rf.workspace("aqil-ihohn").project("deteksi-plat-nomor-kendaraan-k1ldk")
version = project.version(1)
dataset = version.download("yolov11")

# 4.  https://universe.roboflow.com/glob-golb/yolo-number-plate
project = rf.workspace("glob-golb").project("yolo-number-plate")
version = project.version(3)
dataset = version.download("yolov11")

# 5.  https://universe.roboflow.com/i-gusti-fajar/perbandingan-plat
project = rf.workspace("i-gusti-fajar").project("perbandingan-plat")
version = project.version(1)
dataset = version.download("yolov11")

# 6.  https://universe.roboflow.com/deteksi-plat-nomor-pengendara-tanpa-helm/plat-sepeda-motor/dataset/2
project = rf.workspace("deteksi-plat-nomor-pengendara-tanpa-helm").project("plat-sepeda-motor")
version = project.version(2)
dataset = version.download("yolov11")

# 7.  https://universe.roboflow.com/rakha-dimas-putra-thjpu/deteksi-plat-nomor-d5qcc
project = rf.workspace("rakha-dimas-putra-thjpu").project("deteksi-plat-nomor-d5qcc")
version = project.version(1)
dataset = version.download("yolov11")

# 8.  https://universe.roboflow.com/smartproject/deteksi-lisensi-plat
project = rf.workspace("smartproject").project("deteksi-lisensi-plat")
version = project.version(1)
dataset = version.download("yolov11")

# 9.  https://universe.roboflow.com/ali-mustofa-cxrgi/license-plate-indonesia
project = rf.workspace("ali-mustofa-cxrgi").project("license-plate-indonesia")
version = project.version(2)
dataset = version.download("yolov11")

"""# Editing data.yaml name"""

import os

yamlpath = []
for root, dirs, files in os.walk('/content'):
  for file in files:
    if file == 'data.yaml':
      yamlpath.append(os.path.join(root, file))

print('yaml file found')
for path in yamlpath:
  print('-', path)

import yaml

for path in yamlpath:
  print(f'isi yaml {path}')
  with open(path, 'r') as f:
    data = yaml.safe_load(f)
    print(data)

for path in yamlpath:
  with open(path, 'r') as f:
    data = yaml.safe_load(f)
  data['names'] = ['licenseplate']
  with open(path, 'w') as f:
    yaml.dump(data, f)

"""# Merging datasets"""

!mkdir merged_dataset

!mkdir -p merged_dataset/images/train merged_dataset/images/valid merged_dataset/images/test
!mkdir -p merged_dataset/labels/train merged_dataset/labels/valid merged_dataset/labels/test

import shutil
from pathlib import Path

datasets =[
    '/content/license_plate-1',
    '/content/dataset-mix-2',
    '/content/Yolo-Number-Plate-3'
    '/content/Deteksi-Plat-Nomor-Kendaraan-1',
    '/content/License-Plate-Indonesia-2',
    '/content/Deteksi-Plat-Nomor-1',
    '/content/Plat-Sepeda-Motor-2',
    '/content/license_plate-1',
    '/content/Perbandingan-Plat-1',
    '/content/dataset-mix-2',
    '/content/Deteksi-Lisensi-Plat-1',
    '/content/Yolo-Number-Plate-3',
    '/content/Deteksi-Plat-Nomor-Kendaraan-1'
] # bisa ditambah kalau nanti mau nambahin dataset

for ds in datasets:
  for split in ['train', 'valid', 'test']:
    img = Path(f'{ds}/{split}/images')
    lbl = Path(f'{ds}/{split}/labels')
    img_dst = Path(f'merged_dataset/images/{split}')
    lbl_dst = Path(f'merged_dataset/labels/{split}')

    if img.exists():
      for file in img.glob('*'):
        shutil.copy(file, img_dst / file.name)
    if lbl.exists():
      for file in lbl.glob('*'):
        shutil.copy(file, lbl_dst / file.name)

"""# Write new data.yaml file for merged_dataset"""

data_yaml = """
train: /content/merged_dataset/images/train
val: /content/merged_dataset/images/valid
test: /content/merged_dataset/images/test

nc: 1

names: ['licenseplate']
"""

with open('merged_dataset/data.yaml', 'w') as f:
  f.write(data_yaml)

print('ok')

"""# Duplicate check"""

import os

def count_all_images(image_folder):
    total = 0
    for split in ['train', 'val', 'test']:
        path = os.path.join(image_folder, split)
        if not os.path.exists(path):
            continue
        for root, dirs, files in os.walk(path):
            for file in files:
                if file.lower().endswith(('.jpg', '.jpeg', '.png')):
                    total += 1
    print(f"Total gambar di dataset: {total} file")
    return total

total_images = count_all_images("/content/merged_dataset/images")

import hashlib

def count_duplicates(image_folder):
    seen_hashes = set()
    duplicates = []

    for split in ['train', 'val', 'test']:
        path = os.path.join(image_folder, split)
        if not os.path.exists(path):
            continue
        for root, dirs, files in os.walk(path):
            for file in files:
                if file.lower().endswith(('.jpg', '.jpeg', '.png')):
                    file_path = os.path.join(root, file)
                    with open(file_path, 'rb') as f:
                        file_hash = hashlib.md5(f.read()).hexdigest()
                    if file_hash in seen_hashes:
                        duplicates.append(file_path)
                    else:
                        seen_hashes.add(file_hash)

    print(f"Jumlah duplikat ditemukan: {len(duplicates)} file")
    return duplicates

dupe_list = count_duplicates("/content/merged_dataset/images")

def remove_duplicates(image_folder):
    seen_hashes = set()
    duplicate_count = 0

    for split in ['train', 'val', 'test']:
        path = os.path.join(image_folder, split)
        if not os.path.exists(path):
            continue
        for root, dirs, files in os.walk(path):
            for file in files:
                if file.lower().endswith(('.jpg', '.jpeg', '.png')):
                    file_path = os.path.join(root, file)
                    with open(file_path, 'rb') as f:
                        file_hash = hashlib.md5(f.read()).hexdigest()
                    if file_hash in seen_hashes:
                        os.remove(file_path)
                        # Hapus label-nya juga
                        label_path = file_path.replace('/images/', '/labels/').rsplit('.', 1)[0] + '.txt'
                        if os.path.exists(label_path):
                            os.remove(label_path)
                        duplicate_count += 1
                    else:
                        seen_hashes.add(file_hash)
    print(f"Selesai! {duplicate_count} duplikat berhasil dihapus.")

remove_duplicates("/content/merged_dataset/images")

"""# (optional) download merged_dataset as zip file"""

#unzip
!unzip /content/license_plate_epoch8.zip -d /content/license_plate_epoch8

!zip -r /content/license_plate.zip /content/license_plate

"""# Training YOLO"""

!pip install ultralytics --upgrade

from ultralytics import YOLO

model = YOLO("/content/yolo11n.pt")
#model.to("cuda")
model.train(
    data = '/content/merged_dataset/data.yaml',
    epochs = 10,
    imgsz = 640,
    batch = 16,
    name = 'licenseplate-model',
    #device = 'cpu'
)

"""Epochs: 1, 2, 3, 5, 7, 8, 10 =]"""

!zip -r /content/license_plate-model_new.zip /content/runs/detect/licenseplate-model

from google.colab import files
files.download('/content/license_plate-model_new.zip')

"""# OCR"""

!unzip /content/license_plate-model_new.zip -d /content/license_plate-model_new

!pip install easyocr

from ultralytics import YOLO
import cv2
import easyocr
import matplotlib.pyplot as plt
import numpy as np

# Load YOLOv8/YOLOv11 model
model = YOLO("/content/license_plate-model_new/content/runs/detect/licenseplate-model/weights/best.pt")

# Load OCR
reader = easyocr.Reader(['en'])

# Load test image
img_path = "/content/merged_dataset/images/test/r015_jpg.rf.35d132d64553f3fda1eaa85bbbe32f07.jpg"
image = cv2.imread(img_path)

if image is None:
    print("Failed to load image.")
else:
    # Inference (detect license plates)
    results = model(img_path)

    for box in results[0].boxes.xyxy:
        x1, y1, x2, y2 = map(int, box)

        # Tambahkan padding ke bounding box
        pad = 5
        x1, y1 = max(0, x1 - pad), max(0, y1 - pad)
        x2, y2 = min(image.shape[1], x2 + pad), min(image.shape[0], y2 + pad)

        # Crop image
        plate_crop = image[y1:y2, x1:x2]

        # Preprocess: resize, grayscale, threshold, sharpening
        plate_crop = cv2.resize(plate_crop, (400, 120))
        gray = cv2.cvtColor(plate_crop, cv2.COLOR_BGR2GRAY)
        _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)

        # Optional sharpening
        kernel = np.array([[0, -1, 0],
                           [-1, 5, -1],
                           [0, -1, 0]])
        sharp = cv2.filter2D(thresh, -1, kernel)

        # Run OCR
        result = reader.readtext(sharp)

        if result:
            # Urutkan berdasarkan posisi X (dari kiri ke kanan)
            sorted_result = sorted(result, key=lambda x: x[0][0][0])  # sort by x coordinate

            # Gabungkan text dan tampilkan dengan confidence
            texts = []
            for _, text, conf in sorted_result:
                if conf > 0.3:
                    texts.append(text)
                    print(f"Detected: '{text}' (Confidence: {conf:.2f})")

            # Gabungkan semua text
            final_text = " ".join(texts)

            # Auto-correct: replace first "6" with "G" if applicable
            #if final_text.startswith("6"):
            #   final_text = "G" + final_text[1:]

            print(f"\nFinal OCR Result: {final_text}")

            # Visualisasi hasil OCR di gambar
            for bbox, text, conf in sorted_result:
              if conf > 0.3:
                  x0, y0 = map(int, bbox[0])
                  x1, y1 = map(int, bbox[2])
                  cv2.rectangle(plate_crop, (x0, y0), (x1, y1), (255, 0, 0), 2)
                  cv2.putText(plate_crop, text, (x0, y0 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)

        else:
            print("Tidak ada teks terdeteksi")

        # Tampilkan hasil visual
        plt.imshow(cv2.cvtColor(plate_crop, cv2.COLOR_BGR2RGB))
        plt.title("Cropped Plate with OCR Result")
        plt.axis('off')
        plt.show()

"""# Streamlit"""

!pip install streamlit
!wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -O cloudflared
!chmod +x cloudflared

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import cv2
# import numpy as np
# from ultralytics import YOLO
# import easyocr
# from PIL import Image
# import tempfile
# import os
# 
# # Load model YOLO
# model = YOLO("/content/license_plate-model_new/content/runs/detect/licenseplate-model/weights/best.pt")
# 
# # Load OCR
# reader = easyocr.Reader(['en'])
# 
# # Judul aplikasi
# st.title("ğŸš— License Plate Recognition")
# st.markdown("Upload gambar kendaraan, dan sistem akan mendeteksi serta membaca plat nomor menggunakan YOLO dan EasyOCR.")
# 
# # Upload gambar
# uploaded_file = st.file_uploader("Pilih gambar", type=["jpg", "jpeg", "png"])
# 
# if uploaded_file is not None:
#     # Buka dan tampilkan gambar
#     image = Image.open(uploaded_file)
#     st.image(image, caption="Gambar yang diupload", use_column_width=True)
# 
#     # Konversi ke format OpenCV
#     image_np = np.array(image)
#     img_bgr = cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR)
# 
#     # Simpan ke file temporer
#     with tempfile.NamedTemporaryFile(delete=False, suffix=".jpg") as tmp:
#         temp_path = tmp.name
#         cv2.imwrite(temp_path, img_bgr)
# 
#     # Deteksi plat nomor dengan YOLO
#     results = model(temp_path)
# 
#     for box in results[0].boxes.xyxy:
#         x1, y1, x2, y2 = map(int, box)
#         pad = 5
#         x1, y1 = max(0, x1 - pad), max(0, y1 - pad)
#         x2, y2 = min(img_bgr.shape[1], x2 + pad), min(img_bgr.shape[0], y2 + pad)
#         plate_crop = img_bgr[y1:y2, x1:x2]
# 
#         # Preprocessing untuk OCR
#         plate_crop = cv2.resize(plate_crop, (400, 120))
#         gray = cv2.cvtColor(plate_crop, cv2.COLOR_BGR2GRAY)
#         _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
#         kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])
#         sharp = cv2.filter2D(thresh, -1, kernel)
# 
#         # OCR dengan EasyOCR
#         result = reader.readtext(sharp)
# 
#         if result:
#             texts = []
#             for _, text, conf in sorted(result, key=lambda x: x[0][0][0]):
#                 if conf > 0.3:
#                     texts.append(text)
#                     st.write(f"ğŸ“ Detected: '{text}' (Confidence: {conf:.2f})")
# 
#             final_text = " ".join(texts)
#             st.subheader("ğŸ“„ Hasil Akhir OCR:")
#             st.success(final_text)
#         else:
#             st.warning("Tidak ada teks terdeteksi.")
# 
#         # Tampilkan crop hasil plat
#         st.image(cv2.cvtColor(plate_crop, cv2.COLOR_BGR2RGB), caption="Cropped Plate", use_column_width=False)
#

# Jalankan Streamlit di background
!streamlit run app.py &

# Jalankan tunnel Cloudflared
!./cloudflared tunnel --no-autoupdate --url http://localhost:8501